{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Necessary imports\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, BatchNormalization\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport wandb\nfrom wandb.keras import WandbCallback\nimport os","metadata":{"id":"LFRkh5mmAyKX","execution":{"iopub.status.busy":"2022-04-03T15:33:43.935589Z","iopub.execute_input":"2022-04-03T15:33:43.935833Z","iopub.status.idle":"2022-04-03T15:33:43.944702Z","shell.execute_reply.started":"2022-04-03T15:33:43.935799Z","shell.execute_reply":"2022-04-03T15:33:43.943316Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"if os.path.exists('best_model.h5'):\n    os.remove('best_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:34:09.848090Z","iopub.execute_input":"2022-04-03T14:34:09.848376Z","iopub.status.idle":"2022-04-03T14:34:09.853240Z","shell.execute_reply.started":"2022-04-03T14:34:09.848345Z","shell.execute_reply":"2022-04-03T14:34:09.851731Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Fixing a seed value","metadata":{}},{"cell_type":"code","source":"seed = 100\ntf.random.set_seed(seed)\nnp.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:34:14.746020Z","iopub.execute_input":"2022-04-03T14:34:14.746627Z","iopub.status.idle":"2022-04-03T14:34:14.750935Z","shell.execute_reply.started":"2022-04-03T14:34:14.746567Z","shell.execute_reply":"2022-04-03T14:34:14.750220Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#wandb.login()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T08:40:30.591899Z","iopub.execute_input":"2022-04-03T08:40:30.592310Z","iopub.status.idle":"2022-04-03T08:40:30.599743Z","shell.execute_reply.started":"2022-04-03T08:40:30.592275Z","shell.execute_reply":"2022-04-03T08:40:30.599029Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Downloading and unzipping iNaturalist Dataset","metadata":{"id":"6nU-Yk7ZUBg0"}},{"cell_type":"code","source":"!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip","metadata":{"id":"M0_aseuwJiTE","outputId":"b3ce6835-cb52-40cd-b2a7-425bca7b35e5","execution":{"iopub.status.busy":"2022-04-03T14:34:19.445599Z","iopub.execute_input":"2022-04-03T14:34:19.445890Z","iopub.status.idle":"2022-04-03T14:34:41.694970Z","shell.execute_reply.started":"2022-04-03T14:34:19.445858Z","shell.execute_reply":"2022-04-03T14:34:41.694094Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!unzip \"./nature_12K.zip\"","metadata":{"id":"_gCGxwNJUmmw","outputId":"06aa7dcc-1e84-4d86-93ad-bb1c0a1f85a5","execution":{"iopub.status.busy":"2022-04-03T14:39:09.426028Z","iopub.execute_input":"2022-04-03T14:39:09.426287Z","iopub.status.idle":"2022-04-03T14:39:40.615153Z","shell.execute_reply.started":"2022-04-03T14:39:09.426256Z","shell.execute_reply":"2022-04-03T14:39:40.614247Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Preparing data for training","metadata":{"id":"rQUb8FmQHvjL"}},{"cell_type":"code","source":"def train_dataset(augmentation=False, batch_size=64):\n    dir_train = './inaturalist_12K/train'\n    dir_test = './inaturalist_12K/val'\n\n    if augmentation:\n        train_datagen = ImageDataGenerator(rescale=1./255,\n                                          zoom_range=0.3,\n                                          rotation_range=50,\n                                          brightness_range=(0.2, 0.8),\n                                          shear_range=0.2,\n                                          width_shift_range=0.1,\n                                          height_shift_range=0.2,\n                                          horizontal_flip=True,\n                                          vertical_flip=True,\n                                          validation_split=0.1,)\n        test_datagen = ImageDataGenerator(rescale=1./255)\n\n    else:\n        train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n        test_datagen = ImageDataGenerator(rescale=1./255)\n\n    train = train_datagen.flow_from_directory(dir_train, target_size=(200, 200), batch_size=batch_size, subset=\"training\")\n    val = train_datagen.flow_from_directory(dir_train, target_size=(200, 200), batch_size=batch_size, subset=\"validation\")\n    test = test_datagen.flow_from_directory(dir_test, target_size=(200, 200), batch_size=batch_size)\n    \n    return train, val, test;","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:40:30.370813Z","iopub.execute_input":"2022-04-03T14:40:30.371661Z","iopub.status.idle":"2022-04-03T14:40:30.382474Z","shell.execute_reply.started":"2022-04-03T14:40:30.371617Z","shell.execute_reply":"2022-04-03T14:40:30.381798Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def CNN(n_filters, filter_multiplier, dropout, batch_norm, dense_size, act_func= \"relu\", n_classes=10, image_size=200):\n    \n    filter_dim = [3, 3, 5, 5, 7]\n\n    model = Sequential()\n    for i in range(5):\n        #filter_dim = 6-i \n        filter_size = (filter_dim[i], filter_dim[i])\n        if i==0:\n            model.add(Conv2D(n_filters, filter_size, input_shape=(image_size, image_size, 3), data_format=\"channels_last\"))\n        else:\n            model.add(Conv2D(n_filters, filter_size))\n        if batch_norm:\n            model.add(BatchNormalization())\n        if act_func == \"relu\":\n            model.add(Activation(act_func))\n        if act_func == \"leaky\":\n            model.add(keras.layers.LeakyReLU(alpha=0.3))\n            \n        model.add(MaxPooling2D(pool_size=(2,2)))\n        num_filters = int(n_filters * filter_multiplier)\n    \n    model.add(Flatten())\n    model.add(Dense(dense_size))\n    model.add(Dropout(dropout))\n    if act_func == \"relu\":\n        model.add(Activation(\"relu\"))\n    if act_func == \"leaky\":\n        model.add(keras.layers.LeakyReLU(alpha=0.3))\n    model.add(Dense(n_classes))\n    model.add(Activation(\"softmax\"))\n\n    return model","metadata":{"id":"P6pCb459Nh6O","execution":{"iopub.status.busy":"2022-04-03T15:01:12.370432Z","iopub.execute_input":"2022-04-03T15:01:12.370730Z","iopub.status.idle":"2022-04-03T15:01:12.382335Z","shell.execute_reply.started":"2022-04-03T15:01:12.370694Z","shell.execute_reply":"2022-04-03T15:01:12.381536Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Visualizing some training images","metadata":{}},{"cell_type":"code","source":"train, val, test = train_dataset(augmentation=False, batch_size=64)\nimg = train.next()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:40:36.737254Z","iopub.execute_input":"2022-04-03T14:40:36.737820Z","iopub.status.idle":"2022-04-03T14:40:38.124425Z","shell.execute_reply.started":"2022-04-03T14:40:36.737784Z","shell.execute_reply":"2022-04-03T14:40:38.123726Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"idx_to_class = {0: 'Amphibia', 1: 'Animalia', 2: 'Arachnida', 3: 'Aves', 4: 'Fungi', \n                  5: 'Insecta', 6: 'Mammalia', 7: 'Mollusca', 8: 'Plantae', 9: 'Reptilia'}\n\nplt.figure(figsize=(15,15))\nfor i in range(64):\n    plt.subplot(8,8,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(img[0][i])\n    plt.xlabel(idx_to_class[np.argmax(img[1][i])])\nplt.show()","metadata":{"id":"r8Pgem20qT4G","outputId":"1b5a1901-43f9-49a4-baef-ef928353eff6","execution":{"iopub.status.busy":"2022-04-03T10:59:48.698088Z","iopub.execute_input":"2022-04-03T10:59:48.698860Z","iopub.status.idle":"2022-04-03T10:59:51.814767Z","shell.execute_reply.started":"2022-04-03T10:59:48.698821Z","shell.execute_reply":"2022-04-03T10:59:51.813964Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Function to set WandB run name","metadata":{"id":"h0D04xWaHG1Y"}},{"cell_type":"code","source":"def setWandbName(n_filters, filter_multiplier, augment, dropout, batch_norm):\n    \n    batch_norm_dict = {True: \"Y\", False: \"N\"}\n    augment_dict = {True: \"Y\", False: \"N\"}\n\n    name = \"_\".join([\"num\", str(n_filters), \"org\", str(filter_multiplier), \"aug\", augment_dict[augment],\n                      \"drop\", str(dropout), \"norm\", batch_norm_dict[batch_norm]])\n    \n    return name;","metadata":{"execution":{"iopub.status.busy":"2022-04-03T08:41:27.076194Z","iopub.execute_input":"2022-04-03T08:41:27.076417Z","iopub.status.idle":"2022-04-03T08:41:27.084215Z","shell.execute_reply.started":"2022-04-03T08:41:27.076387Z","shell.execute_reply":"2022-04-03T08:41:27.083621Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Function to train the dataset","metadata":{}},{"cell_type":"code","source":"def train_wandb(config= None):\n\n    wandb.init(project=\"Convolutional Neural Networks\", entity=\"cs21s048-cs21s058\")\n    config = wandb.config\n    print(config.augment_data)\n    wandb.run.name = setWandbName(config.n_filters, config.filter_multiplier, config.augment_data, config.dropout, config.batch_norm)\n\n    train, val, test = train_dataset(augmentation=config.augment_data, batch_size=config.batch_size)\n\n    model = CNN(n_filters=config.n_filters, filter_multiplier=config.filter_multiplier,\n                      dropout= config.dropout, batch_norm = config.batch_norm, dense_size= config.dense_size)\n    model.compile(optimizer=keras.optimizers.Adam(config.lr), loss=\"categorical_crossentropy\", metrics=\"categorical_accuracy\")\n    model.fit(train, epochs=config.epochs, validation_data=val, callbacks=[WandbCallback()])","metadata":{"id":"NwHvUd0GDgl-","execution":{"iopub.status.busy":"2022-04-03T14:40:45.741259Z","iopub.execute_input":"2022-04-03T14:40:45.741515Z","iopub.status.idle":"2022-04-03T14:40:45.750452Z","shell.execute_reply.started":"2022-04-03T14:40:45.741487Z","shell.execute_reply":"2022-04-03T14:40:45.749528Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train(n_filters=256, filter_multiplier=0.5, dropout= 0.3, \n          batch_norm = True, dense_size= 128, act_func= \"relu\", \n          batch_size=16, augmentation=True):\n\n    train, val, test = train_dataset(augmentation, batch_size)\n\n    model = CNN(n_filters, filter_multiplier, dropout, batch_norm, dense_size,act_func)\n    model.compile(optimizer=keras.optimizers.Adam(0.0001), loss=\"categorical_crossentropy\", metrics=\"categorical_accuracy\")\n    model.fit(train, epochs=30, validation_data=val)\n    print(\"Testing Model: \")\n    model.evaluate(test, batch_size=64)\n    \n    model.save(\"best_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T11:00:00.744511Z","iopub.execute_input":"2022-04-03T11:00:00.745047Z","iopub.status.idle":"2022-04-03T11:00:00.751237Z","shell.execute_reply.started":"2022-04-03T11:00:00.745008Z","shell.execute_reply":"2022-04-03T11:00:00.750405Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Predict Function","metadata":{}},{"cell_type":"code","source":"def predict(test_data):\n    \n    model = keras.models.load_model(\"best_model.h5\")  #specify the path of the saved best model\n    predictions = model(test[0][0])\n    model.evaluate(test_data, batch_size=64)\n\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-03T11:00:24.366685Z","iopub.execute_input":"2022-04-03T11:00:24.367003Z","iopub.status.idle":"2022-04-03T11:00:24.386044Z","shell.execute_reply.started":"2022-04-03T11:00:24.366966Z","shell.execute_reply":"2022-04-03T11:00:24.383259Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Setting up wandb sweep","metadata":{}},{"cell_type":"code","source":"sweep_config = {\n    \"name\": \"Final Sweep(Bayesian)\",\n    \"description\": \"Tuning hyperparameters\",\n    'metric': {\n      'name': 'val_categorical_accuracy',\n      'goal': 'maximize'\n  },\n    \"method\": \"bayes\",\n    \"project\": \"CS6910_Assignment2\",\n    \"parameters\": {\n        \"n_filters\": {\n        \"values\": [16, 32, 64]\n        },\n        \"filter_multiplier\": {\n            \"values\": [0.5, 1, 2]\n        },\n        \"augment_data\": {\n            \"values\": [True, False]\n        },\n        \"dropout\": {\n            \"values\": [0.3, 0.5]\n        },\n        \"batch_norm\": {\n            \"values\": [False, True]\n        },\n        \"epochs\": {\n            \"values\": [5, 10, 25]\n        },\n        \"dense_size\": {\n            \"values\": [32, 64, 128]\n        },\n        \"lr\": {\n            \"values\": [0.01, 0.001]\n        },\n        \"batch_size\": {\n            \"values\": [64, 128, 256]\n        },\n        \"activation\": {\n            \"values\": [\"relu\", \"leaky\"]\n        },\n    }\n}\n\n# creating the sweep\n#sweep_id = wandb.sweep(sweep_config, project=\"Convolutional Neural Networks\", entity=\"cs21s048-cs21s058\")","metadata":{"id":"MlVwjHpfEfIt","outputId":"446e986c-f7e4-4eae-f6df-a5bfa2798aa2","execution":{"iopub.status.busy":"2022-04-03T08:41:27.615284Z","iopub.execute_input":"2022-04-03T08:41:27.615538Z","iopub.status.idle":"2022-04-03T08:41:27.624206Z","shell.execute_reply.started":"2022-04-03T08:41:27.615503Z","shell.execute_reply":"2022-04-03T08:41:27.623488Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#wandb.agent(\"5qv1kqvj\", function=train_wandb, count=100)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T08:41:27.625330Z","iopub.execute_input":"2022-04-03T08:41:27.626047Z","iopub.status.idle":"2022-04-03T08:41:27.632520Z","shell.execute_reply.started":"2022-04-03T08:41:27.626007Z","shell.execute_reply":"2022-04-03T08:41:27.631756Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Training the model using best hyperparameters:","metadata":{}},{"cell_type":"code","source":"'''\nbest_params{\n    n_filters: 256, \n    filter_multiplier: 0.5,\n    dropout: 0.3, \n    batch_norm: True, \n    dense_size: 128, \n    act_func: \"relu\", \n    batch_size: 16, \n    augmentation: True}\n'''\n\ntrain()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T08:41:27.634847Z","iopub.execute_input":"2022-04-03T08:41:27.636505Z","iopub.status.idle":"2022-04-03T10:30:15.736285Z","shell.execute_reply.started":"2022-04-03T08:41:27.636475Z","shell.execute_reply":"2022-04-03T10:30:15.735546Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Predicting results from the best model","metadata":{}},{"cell_type":"code","source":"predictions = predict(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T11:00:32.292785Z","iopub.execute_input":"2022-04-03T11:00:32.293496Z","iopub.status.idle":"2022-04-03T11:01:06.789286Z","shell.execute_reply.started":"2022-04-03T11:00:32.293426Z","shell.execute_reply":"2022-04-03T11:01:06.788579Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Plotting test data images with predicted labels","metadata":{}},{"cell_type":"code","source":"idx_to_class = {0: 'Amphibia', 1: 'Animalia', 2: 'Arachnida', 3: 'Aves', 4: 'Fungi', \n                  5: 'Insecta', 6: 'Mammalia', 7: 'Mollusca', 8: 'Plantae', 9: 'Reptilia'}\n\n\nlabels= test[0][1]\nplt.figure(figsize=(15,15))\nfor i in range(30):\n        img = test[0][0][i]\n        plt.subplot(10,3,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.tight_layout()\n        plt.imshow(img)\n        #plt.subplots_adjust(bottom=0.2, \n        #            top=0.9, \n        #            wspace=0.4, \n        #            hspace=0.4)\n        plt.xlabel(\"Predicted: \" + idx_to_class[np.argmax(predictions, axis=1)[i]] + \"\\nLabel: \" + idx_to_class[np.argmax(labels, axis=1)[i]])\nplt.savefig('q4b.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T11:01:13.460543Z","iopub.execute_input":"2022-04-03T11:01:13.461101Z","iopub.status.idle":"2022-04-03T11:01:37.195472Z","shell.execute_reply.started":"2022-04-03T11:01:13.461062Z","shell.execute_reply":"2022-04-03T11:01:37.194833Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#wandb.init(project=\"Convolutional Neural Networks\", entity=\"cs21s048-cs21s058\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:31:24.103701Z","iopub.execute_input":"2022-04-03T10:31:24.104055Z","iopub.status.idle":"2022-04-03T10:31:24.112630Z","shell.execute_reply.started":"2022-04-03T10:31:24.104023Z","shell.execute_reply":"2022-04-03T10:31:24.111882Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model(\"../input/best-model/best_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:35:07.682468Z","iopub.execute_input":"2022-04-03T14:35:07.683240Z","iopub.status.idle":"2022-04-03T14:35:11.241308Z","shell.execute_reply.started":"2022-04-03T14:35:07.683198Z","shell.execute_reply":"2022-04-03T14:35:11.240549Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:35:30.182546Z","iopub.execute_input":"2022-04-03T14:35:30.183110Z","iopub.status.idle":"2022-04-03T14:35:30.201709Z","shell.execute_reply.started":"2022-04-03T14:35:30.183069Z","shell.execute_reply":"2022-04-03T14:35:30.201001Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Visualize filters of first layer","metadata":{}},{"cell_type":"code","source":"#Print sizes of all convolution layers:\n\nmodel = keras.models.load_model(\"../input/best-model/best_model.h5\")\nfor layer in model.layers:\n    if 'conv' in layer.name:\n        filters , bias = layer.get_weights()\n        print(layer.name , filters.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T11:01:43.069787Z","iopub.execute_input":"2022-04-03T11:01:43.070059Z","iopub.status.idle":"2022-04-03T11:01:44.591036Z","shell.execute_reply.started":"2022-04-03T11:01:43.070029Z","shell.execute_reply":"2022-04-03T11:01:44.590182Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Visualising filters from 1st layer","metadata":{}},{"cell_type":"code","source":"# Fetching weights from the hidden layer\nfilters , bias = model.layers[0].get_weights()\n\n# normalize filter values for visualizing\nf_min, f_max = filters.min(), filters.max()\nfilters = (filters - f_min) / (f_max - f_min)\n\nn_filters =32\nix=1\nfig = plt.figure(figsize=(20,20))\n\nfig, ax = plt.subplots(8, 4, figsize=(15,20))\nfor i in range(32):\n        ax[int(i/4), i%4].imshow(filters[:, :, :, i])\n        ax[int(i/4), i%4].axis('off')\n        \nplt.savefig('q4c.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T11:01:49.189208Z","iopub.execute_input":"2022-04-03T11:01:49.189782Z","iopub.status.idle":"2022-04-03T11:01:50.303150Z","shell.execute_reply.started":"2022-04-03T11:01:49.189741Z","shell.execute_reply":"2022-04-03T11:01:50.302387Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Visualising feature maps","metadata":{}},{"cell_type":"code","source":"feature_map_model = Model(inputs=model.inputs, outputs=model.layers[0].output)\n\n#taking an image from test data\nplt.imshow(test[0][0][15])\nplt.savefig('q4c_2_img.png')\nplt.axis('off')\n\nfeature_maps = feature_map_model(test[0][0])\nfig, ax = plt.subplots(4, 8, figsize=(12,6))\nfor i in range(32):\n    ax[int(i/8), i%8].imshow(feature_maps[15, :, :, i])\n    ax[int(i/8), i%8].axis('off')\n\nplt.savefig('q4c_2.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T11:13:20.201747Z","iopub.execute_input":"2022-04-03T11:13:20.202003Z","iopub.status.idle":"2022-04-03T11:13:23.436368Z","shell.execute_reply.started":"2022-04-03T11:13:20.201974Z","shell.execute_reply":"2022-04-03T11:13:23.435753Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"plt.savefig('q4c_2.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T10:31:24.145567Z","iopub.status.idle":"2022-04-03T10:31:24.146001Z","shell.execute_reply.started":"2022-04-03T10:31:24.145768Z","shell.execute_reply":"2022-04-03T10:31:24.145790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Guided Backpropagation","metadata":{}},{"cell_type":"code","source":"for p in range(10):\n    index = p\n    file_name = \"img_\"+str(p)+\".jpg\"\n    # Load the image and pre-process\n    image = test[0][0][index]\n    image_tensor = np.expand_dims(image, axis=0)\n\n    # Display the image tensor\n    plt.imshow(image_tensor[0])\n    plt.title(\"True Label: \" + idx_to_class[np.argmax(test[0][1][index])])\n    plt.axis(\"off\")\n    plt.show()\n\n    #print(image_tensor.shape)\n\n    # we are interested in visulaising the output of 10 neurons in the CONV5 layer\n    activation_model = tf.keras.models.Model([model.inputs],[model.get_layer(\"conv2d_4\").output])\n\n    # Creating custom gradients\n    @tf.custom_gradient\n    def guidedRelU(x):\n      def grad(dy):\n        return tf.cast(dy>0,\"float32\") * tf.cast(x>0, \"float32\") * dy\n      return tf.nn.relu(x), grad\n\n    # Apply guided ReLu on activation layers \n    for layer in model.layers[1:]:\n        if hasattr(layer, 'activation') and layer.activation == tf.keras.activations.selu:\n            layer.activation = guidedRelU\n\n    # Finding gradients of the target class score wrt feature maps\n    with tf.GradientTape() as g:\n      inputs = tf.cast(image_tensor, tf.float32)\n      g.watch(inputs)\n      outputs = activation_model(inputs)[0]\n    target_gradient = g.gradient(outputs,inputs)[0]\n\n\n    CONV5_layer_activation = outputs\n\n    layer_names = ['conv2d_4']\n\n    #np.shape(CONV5_layer_activation)= (1,size,size,num_features)\n    #num_features = CONV5_layer_activation.shape[-1]\n    #size = CONV5_layer_activation.shape[1] \n    #print(num_features)\n    #print(size)\n\n    num_features = 10\n    size = 1\n    num_imag_in_row = 1\n    num_cols = num_features // num_imag_in_row\n    display_grid = np.ones((size * num_cols, num_imag_in_row * size))\n\n    k = 1\n    j = 1\n    for col in range(num_cols): \n      for row in range(num_imag_in_row):\n        channel_image = CONV5_layer_activation[j, k, col * num_imag_in_row + row]\n        display_grid[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image\n\n    scale = 1. / size\n    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n    plt.title(layer_names)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto',cmap='gray')  \n    plt.show() \n\n    # Guided backpropagation gradient visualisation\n\n    grad_image = np.dstack((\n                target_gradient[:, :, 0],\n                target_gradient[:, :, 1],\n                target_gradient[:, :, 2],\n            ))       \n    grad_image = grad_image - np.min(grad_image)\n    grad_image = grad_image/grad_image.max()\n    imgplot = plt.imshow(grad_image)\n    plt.axis(\"off\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T11:06:00.100010Z","iopub.execute_input":"2022-04-03T11:06:00.100385Z","iopub.status.idle":"2022-04-03T11:06:18.056196Z","shell.execute_reply.started":"2022-04-03T11:06:00.100348Z","shell.execute_reply":"2022-04-03T11:06:18.055547Z"},"trusted":true},"execution_count":23,"outputs":[]}]}